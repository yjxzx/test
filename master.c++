```html
<h2 align="center">
  麻省理工学院 (MIT) 18.06, 2025年春季学期<br />
  线性代数
</h2>

欢迎来到 MIT 18.06：线性代数！2025年春季学期的课程信息、资料和链接记录如下。往年学期的课程资料已归档在本代码仓库的[其他分支](https://docs.github.com/en/repositories/configuring-branches-and-merges-in-your-repository/managing-branches-in-your-repository/viewing-branches-in-your-repository)中。您可以立即开始，阅读 Strang 教授撰写的这篇[课程简介](https://github.com/mitmath/1806/blob/master/notes/Introduction%20to%20Linear%20Algebra%206th%20edition%20and%20A%20%3D%20CR_04.pdf)。

课程目录描述：*关于矩阵理论和线性代数的基础课程，强调在其他学科中有用的主题，包括方程组、向量空间、行列式、特征值、奇异值分解和正定矩阵。应用于最小二乘近似、微分方程的稳定性、网络、傅里叶变换和马尔可夫过程。使用线性代数软件。与 18.700 相比，更侧重于矩阵算法和多种应用。*

**授课教师**：[Nike Sun 教授](https://math.mit.edu/~nsun/)

**教材**：[《线性代数导论：第六版》](http://eduapps.mit.edu/textbook/books.html?Term=2023SP&Subject=18.06)。

**详细的课堂讲义发布在 Canvas 上（仅限已注册学生访问）。**

## 课程内容与摘要

### 第1讲 (2025年2月3日 周一)

* $\mathbb{R}^2$ 中的向量，并推广到 $\mathbb{R}^N$（N维空间）中的向量。
* 向量运算：加法和标量乘法。两种运算结合：线性组合。
* 向量集合 $\lbrace u_1,\ldots,u_k\rbrace$ 的生成空间 (span) 是这些向量所有线性组合的集合：我们在课堂上讨论了一些例子。
* 矩阵乘以向量的定义：$Ax$，其中 $A$ 是一个 $M \times N$ 矩阵，$x$ 在 $\mathbb{R}^N$ 中。

**阅读材料：** Strang 教材第1章。

### 第2讲 (2025年2月5日 周三)
* 点积、向量长度、余弦公式。
* 求解线性方程组 Ax=b 的高斯消元算法：将矩阵简化为行阶梯形 (REF)，然后进行回代。课堂上演示了一个例子。
* 矩阵乘以矩阵的定义：$AB=X$，其中 $A$ 是 $M \times N$ 矩阵，$B$ 是 $N \times P$ 矩阵，$X$ 是 $M \times P$ 矩阵。* 我们解释了如何将高斯消元操作视为矩阵乘法操作：高斯消元的步骤对应于将 $Ax=b$ 变为 $(G1)Ax=(G1)b$，再变为 $(G2)(G1)Ax=(G2)(G1)b$，依此类推。

**阅读材料：** Strang 教材 2.1-2.2节。

### 第3讲 (2025年2月7日 周五)
* 使用矩阵乘法来编码操作，回顾了高斯消元的例子。
* 高斯-若尔当消元法有几个额外步骤，可将系统变为简化行阶梯形 (RREF) — 我们在同一个例子中进行了此操作，同样使用了矩阵乘法。
* 在该例子中，最终的 RREF 系统是 $(G5)(G4)(G3)(G2)(G1)Ax=(G5)(G4)(G3)(G2)(G1)b=c$。此外，我们发现 $(G5)(G4)(G3)(G2)(G1)A = I_3$，即 $3 \times 3$ 的单位矩阵。在这个例子中，这让我们能直接读出 $x = c$。
* 我们回顾了矩阵乘法的基本规则：结合律 $A(BC)=(AB)C$，分配律 $A(B+C)=AB+AC$，但**不满足交换律**：$AB$ 和 $BA$ 通常不相等！
* 逆矩阵：如果 $A$ 是一个 $n \times n$ 矩阵，若存在一个同样是 $n \times n$ 的矩阵 $A^{-1}$，使得 $AA^{-1} = A^{-1}A = I_n$（$n \times n$ 单位矩阵），则称 $A$ 是可逆的。
* 如果 $A$ 可逆，则高斯-若尔当消元法将 $(A|b)$ 转化为 $(I|c)$。此外，它还将 $(A|I)$ 转化为 $(I|A^{-1})$。
* 方块矩阵不一定是可逆的，我们讨论了一些例子。

**阅读材料：** Strang 教材 2.3节。

### 第4讲 (2025年2月10日 周一)
* 如果 $A$ 的列向量的某个非平凡线性组合为零，则称它们是线性相关的：这可以写作 $Ax=0$ 且 $x$ 非零。如果 $A$ 是一个列向量线性相关的方块矩阵，那么 $A$ 不可能是可逆的。我们讨论了一些例子。
* 我们定义了矩阵的列空间 $C(A)$。一个 $m \times n$ 矩阵 $A$ 可以看作是从 $\mathbb{R}^n$ 到 $\mathbb{R}^m$ 的一个函数/映射，将输入 $x \in \mathbb{R}^n$ 映射到输出 $Ax \in \mathbb{R}^m$。列空间 $C(A)$ 正是这个映射的像。方程 $Ax=b$ 有解当且仅当 $b$ 属于 $C(A)$。
* 我们定义了一般的向量空间和子空间，并讨论了一些例子。

**阅读材料：** Strang 教材 3.1节。

### 第5讲 (2025年2月12日 周三)
* 定义了零空间 $N(A)$ 为所有满足 $Ax=0$ 的向量 $x$ 的集合。
* 注意，如果 $A$ 是 $m \times n$ 矩阵，则 $C(A)$ 是 $\mathbb{R}^m$ 的子空间，而 $N(A)$ 是 $\mathbb{R}^n$ 的子空间。（译者注：原文有误，此处已根据定义更正。C(A) 是 R^m 的子空间，N(A) 是 R^n 的子空间。）
* 可逆的行操作（如高斯-若尔当消元法中的操作）不影响零空间，因此如果 $R$ 是 $A$ 的 RREF，则 $N(A) = N(R)$。
* 我们讨论了几个计算 $N(A)$ 的例子。我们还注意到，在我们所有的例子中，dim C(A) + dim N(A) = n。

**阅读材料：** Strang 教材 3.2节。

### 第6讲 (2025年2月14日 周五)
* 在这节课上，我们讨论了线性方程组 Ax=b 的通解。
* 基本原则：如果 $b$ 不在 $C(A)$ 中，则无解。如果 $b$ 在 $C(A)$ 中，则必须存在至少一个“特解”，记为 $x_0$。那么 $Ax=b$ 的所有解的集合就是 $x_0 + x'$ 的形式，其中 $x_0$ 是特解，$x'$ 是来自零空间 $N(A)$ 的任意向量。
* 求解的一般方法：
    * 给定 $(A|b)$，应用高斯-若尔当消元法将其转换为 RREF 系统 $(R|c)$。
    * 如果 RREF 系统中有一行形如 0 = 非零数，则出现矛盾，此时 $b$ 不在 $C(A)$ 中，无解。
    * 否则，将自由变量设为零以找到一个特解 $x_0$。
    * 单独求解零空间 $N(A)$。
    * 那么 $Ax=b$ 的所有解的集合就是形如 $x_0 + x'$ 的向量集合，其中 $x_0$ 是特解，$x'$ 是来自 $N(A)$ 的任意向量。

**阅读材料：** Strang 教材 3.3节。

### 第7讲 (2025年2月18日 周二)
* 在本节课中，我们令 $v^1, \ldots, v^n$ 为 $n$ 个向量的列表，每个向量都在空间 $\mathbb{R}^m$ 中。令 $A$ 是以 $v^1, \ldots, v^n$ 为列的 $m \times n$ 矩阵。
    * 如果向量 $\lbrace v^1, ..., v^n\rbrace$ 的某个非平凡线性组合等于零，则称它们是**线性相关**的：这对应于 $N(A)$ 严格大于 $\lbrace 0\rbrace$。否则，我们称它们是**线性无关**的：这对应于 $N(A) = \lbrace 0\rbrace$。
    * 向量空间 $V$ 的一个**基**是一组既能生成 $V$ 又线性无关的向量。我们讨论了空间 $\mathbb{R}^n$ 的标准基 $\lbrace e^1, ..., e^n\rbrace$。
    * 令 $V = \text{span} \lbrace v^1, ..., v^n\rbrace$。那么 $V$ 与 $C(A)$ 相同。如果 $\lbrace v^1, ..., v^n\rbrace$ 是线性无关的，那么它们构成 $V$ 的一个基。
* 更一般地，执行高斯-若尔当消元，令 $R = GA$ 是 $A$ 的 RREF。那么 $C(R) = G C(A)$。
    * $R$ 的主元列构成 $C(R)$ 的一个基，而 $A$ 中对应的列构成 $C(A)$ 的一个基。
    * 注意 rank(A) = R 中的主元数 = dim C(R) = dim C(A)。同时，R 中的自由变量数 = dim N(A)。
    * 总共有 n 列，每列要么是主元列，要么是自由列，所以 n = 主元数 + 自由变量数 = dim C(A) + dim N(A)：这就是**秩-零化度定理**。
* 最后，我们回顾了如果 $A$ 是一个 $m \times n$ 矩阵，我们将其视为从 $\mathbb{R}^n$ 到 $\mathbb{R}^m$ 的映射，将 $\mathbb{R}^n$ 中的 $x$ 映射到 $\mathbb{R}^m$ 中的 $Ax$。

**阅读材料：** Strang 教材 3.4节。

**注意：** 你应该能够仅使用第1-6讲所涵盖的信息，以及第一次考试前布置的作业、习题课和阅读材料来完成第一次考试的所有题目。然而，由于本课程的所有主题都紧密相连，第7讲的材料也可能对考试有帮助，你也可以在考试中使用这些材料。本课程的所有考试都是闭卷、无笔记的。

------------------------------------------------------

### 第一次考试 (2025年2月19日 周三)

------------------------------------------------------

### 第8讲 (2025年2月21日 周五)

* 我们从**矩阵转置** $A^t$ 的定义开始讲起。
    * 注意一般情况下 $(A^t)^t=A$，以及 $(AB)^t = B^t A^t$。
    * 如果 $A=A^t$，我们称 $A$ 是**对称的**。只有方块矩阵才能是对称的。
* 我们讨论了**矩阵的四个基本子空间**，以及如何计算它们。在此过程中，令 A 为一个 $m \times n$ 矩阵，令 $R = GA$ 为其 RREF。因此 $G$ 是一个编码高斯-若尔当行操作的可逆 $m \times m$ 矩阵。
    * 列空间 $C(A) = G^{-1} C(R)$。这是 $\mathbb{R}^m$ 的一个子空间。
    * 零空间 $N(A) = N(R)$。这是 $\mathbb{R}^n$ 的一个子空间。
    * 行空间 $C(A^t) = C(R^t)$。这是 $\mathbb{R}^n$ 的一个子空间。（译者注：原文为 C(R^t)，根据上下文及标准教材，此处已更正。）
    * 左零空间 $N(A^t) = G^t N(R^t)$。这是 $\mathbb{R}^m$ 的一个子空间。

上述主张的正式推理：

1. 列空间：$C(A) = {Ax : x \in \mathbb{R}^n}$ 且 $C(R) = {GAx : x \in \mathbb{R}^n}$。因此 $b' \in C(R) \Leftrightarrow$ 存在某个 $x$ 使得 $b' = GAx \Leftrightarrow$ 存在某个 $x$ 使得 $G^{-1}b' = Ax \Leftrightarrow G^{-1}b' \in C(A)$。这证明了 $C(A) = G^{-1} C(R)$。
2. 零空间：$N(A) = \lbrace x : Ax = 0\rbrace$ 且 $N(R) = \lbrace x : GAx = 0\rbrace$。因为 $G$ 可逆，所以 $Ax = 0 \Leftrightarrow GAx = 0$。这证明了 $N(A) = N(R)$。
3. 行空间：回顾 $R^t = (GA)^t = A^t G^t$。$C(A^t) = \lbrace A^t x : x \in \mathbb{R}^m\rbrace$ 且 $C(R^t) = \lbrace A^t G^t x : x \in \mathbb{R}^m\rbrace$。因为 $G$ 可逆，所以 $G^t$ 也可逆。当 $x$ 遍历整个 $\mathbb{R}^m$ 时，$G^t x$ 也遍历整个 $\mathbb{R}^m$。因此 $C(A^t) = C(R^t)$。
4. 左零空间：(***黑板上有一个笔误，请仔细阅读这一条。***) $N(A^t) = \lbrace x : A^t x = 0\rbrace$ 且 $N(R^t) = \lbrace x : A^t G^t x = 0\rbrace$。因此 $x \in N(R^t) \Leftrightarrow A^t G^t x = 0 \Leftrightarrow G^t x \in N(A^t)$。这证明了 $N(A^t) = G^t N(R^t)$。

在课堂上，我们通过一个小例子计算了四个基本子空间。我们验证了列空间和左零空间是 $\mathbb{R}^m$ 中的正交子空间，而行空间和零空间是 $\mathbb{R}^n$ 中的正交子空间。

**阅读材料：** Strang 教材 3.5节。

### 第9讲 (2025年2月24日 周一)
* 在本节课中，我们回顾了 $m \times n$ 矩阵 $A$ 的四个基本子空间。
* 我们通过一个例子，演示了如何使用 RREF $R = GA$ 来计算 $A$ 的四个子空间。
* 维度：列空间和行空间的维度都是 r = rank(A)。零空间的维度是 $n - r$，而左零空间的维度是 $m - r$。
* 我们讨论了这样一个事实：在 $\mathbb{R}^n$ 中，行空间和零空间互为正交补。在 $\mathbb{R}^m$ 中，列空间和左零空间互为正交补。

**阅读材料：** Strang 教材 4.1节。

### 第10讲 (2025年2月26日 周三)

* 我们讨论了 $\mathbb{R}^n$ 的两个子空间满足以下关系的含义：
    * 互补
    * 正交
    * 互为正交补
* 特别是：
    * 如果 $V$ 和 $W$ 是 $\mathbb{R}^n$ 的互补子空间，那么任何 $x \in \mathbb{R}^n$ 都可以唯一地写成 $x = v + w$，其中 $v$ 来自 $V$，$w$ 来自 $W$。
    * 如果 $V$ 和 $W$ 此外还是互为正交补，那么 $v$ 是 $x$ 在 $V$ 上的正交投影，而 $w$ 是 $x$ 在 $W$ 上的正交投影。记为 $v = \text{proj}_V x$ 和 $w = \text{proj}_W x$。
* 我们讨论了正交投影的几何解释：
    * $v = \text{proj}_V x$ 是 $V$ 中离 $x$ 最近的唯一向量。
    * 等价地，$v = \text{proj}_V x$ 是 $V$ 中唯一的向量，使得 $(x-v)$ 垂直于 $V$。
    * 我们使用后一种特性来计算 $\text{proj}_Y x$，其中 $Y$ 是由 $\mathbb{R}^n$ 中单个非零向量 $y$ 生成的空间。

**阅读材料：** Strang 教材 4.2节。

### 第11讲 (2025年2月28日 周五)
* 我们讨论了正交投影的一般公式。
* 投影到一维子空间 $Y = \text{span}\lbrace y\rbrace$，其中 $y$ 是 $\mathbb{R}^n$ 中的单位向量：$\text{proj}_Y(x) = P_Y x$，其中 $P_Y = yy^t$。注意 $P_Y$ 是一个 $n \times n$ 的对称矩阵。它的列空间正是一维空间 $Y$，因此 $P_Y$ 的秩为1。
* 投影到 $\mathbb{R}^n$ 的一个一般子空间 $V$，其中 $\text{dim } V = r < n$：首先将 $V$ 表示为 $V = C(A)$，其中 $A$ 是一个 $n \times r$ 矩阵，其列构成了 $V$ 的一个基。我们在课堂上证明了 $v = \text{proj}_V(b) = P_V b$，其中 $P_V = A(A^t A)^{-1} A^t$。这是一个 $n \times n$ 的对称矩阵。它的列空间正是 $V = C(A)$，因此 $P_V$ 的秩为 $r$。
    * **声明：** 如果 $A$ 是一个秩为 $r$ 的 $n \times r$ 矩阵，那么 $A^t A$ 是可逆的。我们在课堂上陈述了这个事实，并用它来定义 $P_V$。我们尚未证明这一事实，将在未来的讲座中进行证明。
    * 注意到 $v = A x$，其中 $x = (A^t A)^{-1} A^t b$。这使得距离 $\Vert Ax-b \Vert$ 最小化，我们称之为**最小二乘解**。
* 最后，我们看了一些投影矩阵公式的例子：
    * 在一维情况 $Y = \text{span}\lbrace y\rbrace$ 中，其中 $y$ 是一个单位向量，我们取 $A = y$，恢复了公式 $P_Y = yy^t$。
    * 如果我们有 $V$ 的一个标准正交基 $\lbrace u^1, ..., u^r\rbrace$，那么 $P_V = P_1 + ... + P_r$，其中 $P_j = u^j(u^j)^t$ 是到 $\text{span}\lbrace u^j\rbrace$ 上的正交投影。

**阅读材料：** Strang 教材 4.3节。

### 第12讲 (2025年3月3日 周一)
* 正如我们之前学到的，如果 b 不在列空间 $C(A)$ 中，方程 $Ax=b$ 无解。在这种情况下，可以转而寻求最小二乘 (LS) 解：即最小化下式的 x 的选择
```math
\|Ax-b\|^2 = \sum_i [(Ax)_i - b_i]^2
```
* 这意味着 $v=Ax$ 应该恰好是 $b$ 在 $C(A)$ 上的投影，因此根据我们之前学到的知识，我们知道 $v = A(A^t A)^{-1}A^t b$，从而 $x=(A^t A)^{-1}A^t b$。（译者注：原文为“v=Ax 应该恰好是 x 在 C(A) 上的投影”，根据上下文应为 b 在 C(A) 上的投影，此处已更正。）
* 应用：给定数据集 $(a_i,b_i)$ for $1\le i \le 1000$，我们讨论了如何找到：
  * 实现最小二乘拟合的无截距直线：$b=xa$，其中 $x$ 是斜率；
  * 实现最小二乘拟合的有截距直线：$b = x_0 + x_1 a$，其中 $x_0$ 是截距，$x_1$ 是斜率；
  * 实现最小二乘拟合的三次函数：$b = x_0 + x_1 a + x_2 a^2 + x_3 a^3$。

**阅读材料：** Strang 教材 4.3节。

### 第13讲 (2025年3月5日 周三)
* 我们学习了**Gram-Schmidt 正交化过程**：给定 $\mathbb{R}^n$ 的子空间 $V$ 的一个基 $(v_1,\ldots,v_r)$，该过程能产生一个 $V$ 的标准正交基 $(u_1,\ldots,u_r)$。
* Gram-Schmidt 过程可以总结为 **QR 分解**：$A=QR$，其中：
  * $A$ 是以 $v_1,\ldots,v_r$ 为列的 $n\times r$ 矩阵；
  * $Q$ 是以 $u_1,\ldots,u_r$ 为列的 $n\times r$ 矩阵；
  * $R$ 是一个 $r\times r$ 矩阵，包含了将 $v$ 向量与 $u$ 向量关联起来的系数。特别地，$R$ 是一个对角线元素非零的上三角矩阵，可以通过回代法求逆。

**阅读材料：** Strang 教材 4.4节。

### 第14讲 (2025年3月7日 周五)
* 设 $A$ 是一个秩为 $r$ 的 $r\times n$ 矩阵，其中 $r<n$。这意味着列空间 $C(A)=\mathbb{R}^r$：因此，对于任何 $b\in\mathbb{R}^r$，方程 $Ax=b$ 至少有一个解 $\tilde{x}$。我们还知道零空间 $N(A)$ 是 $\mathbb{R}^n$ 的一个维数为 $n-r>0$ 的子空间。因此，实际上 $Ax=b$ 有无穷多个解，因为对于任何来自 $N(A)$ 的 $x'$，$\tilde{x}+x'$ 也是一个解。于是我们可以问，范数最小的解 $x$ 是什么？任何解 $x$ 都可以分解为 $x^\parallel + x^\perp$，其中 $x^\parallel \in N(A)$ 而 $x^\perp\in N(A)^\perp = C(A^\top)$（$A$ 的行空间）。我们在课堂上讨论了 $Ax=b$ 的最小范数解恰好是 $x^\perp$。如果我们有 $A^\top$ 的 QR 分解 $A^\top=QR$，那么 $Ax=b$ 可以重新整理得到 $x^\perp = QQ^\top x = Q(R^\top)^{-1}b$。
* 如果 $A$ 是一个 $m\times n$ 矩阵，它的**矩阵伪逆**是一个 $n\times m$ 矩阵 $A^+$，其作用如下：
  * 给定 $y\in\mathbb{R}^m$，设 $b$ 是 $y$ 在列空间 $C(A)$ 上的正交投影。（译者注：原文为 y 在 R^n 中，根据上下文应为 R^m，此处已更正。）
  * 设 $x^\perp$ 是方程 $Ax=b$ 的最小范数解。
那么 $A^+$ 就是那个作用为 $A^+y=x^\perp$ 的 $n\times m$ 矩阵。
* 计算伪逆的两个例子：
  * 如果 $A$ 是秩为 $r$ 的 $r\times n$ 矩阵，那么上述计算告诉我们，如果我们有 $A^\top$ 的 QR 分解 $A^\top=QR$，则 $A^+=Q(R^\top)^{-1} = A^\top (AA^\top)^{-1}$。
  * **（已更正；此处之前有笔误！）** 如果 $A$ 是秩为 $r$ 的 $n\times r$ 矩阵，伪逆应该首先将 $y$ 映射到其在 $C(A)$ 上的正交投影，即 $b = A(A^\top A)^{-1} A^\top y$，它位于 $C(A)$ 中。因此 $Ax=b$ 有唯一解，由 $x=(A^\top A)^{-1} A^\top y$ 给出。由此得出 $A^+ = (A^\top A)^{-1} A^\top$。

**阅读材料：** Strang 教材 4.5节。

### 第15讲 (2025年3月10日 周一)
* 如果 $A$ 是一个 $n\times n$ 的方块矩阵，它的**行列式**是线性变换 $A:\mathbb{R}^n\to\mathbb{R}^n$ 缩放 $n$ 维体积的**带符号**的因子。（译者注：原文为“square determinant”，应为“square matrix”，此处已更正。）
* 一些关键事实：
  * 乘积公式：$\det(AB)=(\det A)(\det B)$。
  * $\det A\neq0$ 当且仅当 $A$ 可逆。
  * 上三角矩阵的行列式是对角线元素的乘积。
* 我们讨论了几种 $2\times 2$ 矩阵 $A$ 的情况：单位正方形 $S$ 映射为一个平行四边形 $AS$，而 $\det A$ （不计符号）是 $AS$ 的二维体积（面积）。
* 计算 $\det A$ （不计符号）的两种方法：
  * 使用（广义）QR 分解：$A=QR$，其中 $Q$ 是一个 $n\times n$ 正交矩阵，$R$ 是一个上三角矩阵（对角线上可能有零）。那么 $\det Q=\pm1$，所以 $\det A = \pm(\det R)$。
  * 使用高斯消元：$GA=\tilde{A}$，其中 $\tilde{A}$ 是行阶梯形 (REF)，$G$ 是一系列行交换或行消元矩阵的乘积。那么 $\det G = \pm1$，所以 $\det A = \pm(\det\tilde{A})$。

**阅读材料：** Strang 教材 5.1节。

### 第16讲 (2025年3月12日 周三)
* 我们讨论了 $n\times n$ 矩阵行列式的“大公式”，$\det A = \sum_\sigma (\textup{sgn }\sigma)\prod_{i=1}^n a_{i,\sigma(i)}$。求和遍及 $\{1,\ldots,n\}$ 的所有 $n!$ 个排列，$\textup{sgn }\sigma$ 表示排列 $\sigma$ 的符号：如果 $\sigma$ 是偶数次交换的复合，则为 $+1$；如果是奇数次交换的复合，则为 $-1$。我们解释了这个公式可以从行列式的多重线性性质推导出来。
* 在大多数情况下，计算 $\det A$ 更有效的方法是通过高斯消元：$R = G_k \cdots G_1 A$。$R$ 是行阶梯形，因此它是上三角矩阵，其行列式就是其对角线元素的乘积。每个 $G_i$ 编码一个初等行操作：如果 $G_i$ 编码一个行交换，从大公式可知 $\det G_i=-1$。否则，如果 $G_i$ 编码一个消元操作，那么 $G_i$ 是一个对角线上全为 1 的下三角矩阵，此时 $\det G_i=1$。因此 $\det A=(-1)^s\det R$，其中 $s$ 是高斯消元中的行交换次数。

**阅读材料：** Strang 教材 5.2节。

### 第17讲 (2025年3月14日 周五)
* 我们讨论了行列式的拉普拉斯展开，这可以看作是组织上次“大公式”的一种方式。
* 我们考虑了一个循环矩阵的例子；参见 https://en.wikipedia.org/wiki/Circulant_matrix。按照维基百科的记法，我们的例子中 $c_0=1$，$c_1=z$，所有其他 $c_j=0$。我们讨论了如何使用“大公式”以及沿第一行进行拉普拉斯展开来计算这个矩阵的行列式。

**阅读材料：** Strang 教材 5.3节。

### 第18讲 (2025年3月17日 周一)
* 在这节课上，我们为周三的考试做了一些复习和例题。
* 如果 $M=I+vv^\top$，我们解释了如何计算出 $M^{-1} = I-(1+\|v\|^2)^{-1}vv^\top$。
* 设 $I$ 是 $r\times r$ 的单位矩阵，$v$ 是 $\mathbb{R}^r$ 中的一个向量。我们计算了矩阵
```math
A = \begin{pmatrix} I & v  \\ 0 & 0 \end{pmatrix}
```
的伪逆。

------------------------------------------------------

### 第二次考试 (2025年3月19日 周三)

------------------------------------------------------

### 第19讲 (2025年3月21日 周五)
* 在这节课上，我们回顾了行列式的拉普拉斯展开（也称代数余子式展开）。
* 给定一个 $n\times n$ 矩阵 $A$，其 $(i,j)$ **余子式**是通过移除 $A$ 的第 $i$ 行和第 $j$ 列得到的 $(n-1)\times(n-1)$ 矩阵 $M_{i,j}$。
* 我们将 $(i,j)$ **代数余子式**定义为 $C_{i,j}=(-1)^{i+j}\det M_{i,j}$。**代数余子式矩阵**是以 $C_{i,j}$ 为元素的 $n\times n$ 矩阵 $C$。
* **伴随矩阵**是 $X=C^\top$。我们在课堂上推导出，如果 $A$ 可逆，那么 $A^{-1}=(1/\det A) X$。
* 我们还用它来推导求解线性系统 $Ax=b$ 的**克莱姆法则**。

**阅读材料：** 完成 Strang 教材第5章。

### 第20讲 (2025年3月31日 周一)
* 在本节课开始时，我们讨论了对角矩阵的作用方式很简单。
* 一个（方块）矩阵 $A$ 是**可对角化的**，如果它能通过方程 $A=EDE^{-1}$ 与一个对角矩阵相关联，其中 $E$ 是 $n\times n$ 可逆矩阵，$D$ 是 $n\times n$ 对角矩阵。
* **注意：并非所有方块矩阵都是可对角化的！** 然而，这是一个重要且有用的概念。
* 设 $E$ 的列为 $v^1,\ldots,v^n$，设 $D$ 的对角线元素为 $d_1,\ldots,d_n$。我们证明了 $v^j$ 是 $A$ 的一个**特征向量**，其**特征值**为 $d_j$。
* 由于 $E$ 是可逆的（根据定义），它的列构成了 $\mathbb{R}^n$ 的一个基，称为 $A$ 的**特征基**。$A$ 在特征基下的作用是对角的。
* 我们解释了 $E$ 和 $E^{-1}$ 可以被看作是实现**基变换**：$E^{-1}$ 从标准坐标映射到特征基坐标，而 $E$ 从特征基坐标映射到标准基坐标。
* 我们还讨论了一些具体例子。在未来的讲座中，我们将学习如何计算矩阵的特征值和特征向量。

**阅读材料：** 开始阅读 Strang 教材第6章。

### 第21讲 (2025年4月2日 周三)
* 设 $A$ 为一个 $n\times n$ 的方块矩阵。$A$ 的一个**特征向量**是一个非零向量 $v\in\mathbb{R}^n$，使得对于某个标量 $\lambda$（**特征值**），有 $Av=\lambda v$。我们将允许 $\lambda$ 是实数或复数，所以一般情况下 $\lambda\in\mathbb{C}$。
* 特征值为 $\lambda=0$ 的特征向量就是一个零空间中的向量。
* 一般来说，对于任何 $\lambda$，特征值为 $\lambda$ 的特征向量是零空间 $N(A-\lambda I)$ 中的任何非零向量。
* 因此，$A$ 的特征值正是 $p_A(\lambda)=\det(A-\lambda I)$ 的根，即 $A$ 的**特征多项式**。
* 令 $\alpha$ 表示 $A$ 的**迹**（其对角线元素之和）。从行列式公式可以得出，$p_A(\lambda)$ 是一个关于 $\lambda$ 的 $n$ 次多项式，形式为
```math
p_A(\lambda) = (-1)^n\lambda^n +(-1)^{n-1} \alpha \lambda^{n-1} + \ldots + \det A\,.
```
* **代数基本定理**告诉我们 $p_A(\lambda)$ 有 $n$ 个根 $\lambda_1,\ldots,\lambda_n$，并且可以分解为
```math
p_A(\lambda) = (-1)^n \prod_{j=1}^n(\lambda-\lambda_j)\,.
```
* 特征值正是这些根 $\lambda_j$。它们可能是复数值，并且可能存在重根。
* 特征值 $\lambda$ 的**代数重数**是它作为特征多项式根的出现次数。
* 特征值 $\lambda$ 的**几何重数**是其**特征空间** $N(A-\lambda I)$ 的维数。
* 通常情况下，$1\le \textup{几何重数} \le \textup{代数重数}$。我们将在下节课进一步讨论。

**阅读材料：** Strang 教材 6.1-6.2节。

### 第22讲 (2025年4月4日 周五)

* 设 $A$ 为一个 $n\times n$ 的方块矩阵。我们上次讨论过，特征多项式 $p_A(\lambda)$ 是一个关于 $\lambda$ 的 $n$ 次多项式。代数基本定理告诉我们它有 $n$ 个根 $\lambda_1,\ldots,\lambda_n$，这些正是 $A$ 的特征值。这些根可能是复数值，也可能存在重根。
* 特征值 $\lambda$ 的**代数重数**是它作为特征多项式根的出现次数。
* 特征值 $\lambda$ 的**几何重数**是其**特征空间** $N(A-\lambda I)$ 的维数。
* 通常情况下，$1 \le \textup{几何重数} \le \textup{代数重数}$。
* 代数重数之和等于总根数 $n$。不同特征值的特征空间是线性无关的，因此几何重数之和等于所有特征空间的总维度。矩阵 $A$ **可对角化**当且仅当后者的和等于 $n$，这意味着所有特征值的几何重数必须等于其代数重数。这在一般情况下并不保证。
* 一个特殊情况是所有 $n$ 个根都是不同的。在这种情况下，所有特征值的几何重数和代数重数都必须为 1，所以这种情况下矩阵 $A$ 总是可对角化的。如果根不完全不同，那么 $A$ 可能可对角化，也可能不可。
* 如果 $A$ 不可对角化，那么它有一个若尔当标准型 (JCF)，可以看作是对角化的推广。（在 $A$ 可对角化的特殊情况下，JCF 与对角化形式相同。）

**阅读材料：** 完成阅读 Strang 教材 6.1-6.2节。

### 第23讲 (2025年4月7日 周一)

* 我们讨论了即使对于实矩阵，特征值和特征向量也可能是复数值，并讲解了一个例子。
* 一般来说，如果 $A$ 是一个实 $n\times n$ 矩阵，那么它的特征多项式具有实系数。这意味着 $A$ 的非实数特征值必须成共轭对出现。（例如，这也意味着如果 $A$ 是 $n\times n$ 且 $n$ 为奇数，那么 $A$ 必须至少有一个实特征值）。
* 我们讨论了复数的一些基本概念，包括共轭和模。我们还讨论了复向量、共轭转置操作以及复向量的范数。
* 最后，我们讲了**谱定理**，该定理指出，如果 $A$ 是 $n\times n$ 的实对称矩阵，那么它具有全为实数的特征值和特征向量，以及一个标准正交的特征基。我们可以将其写为 $A=EDE^\top$，其中 $D$ 和 $E$ 都是实矩阵，且 $E$ 是一个正交矩阵。课堂上我们还给出了谱定理的部分证明。

**阅读材料：** Strang 教材 6.3节，以及 6.4节的前三页。

### 第24讲 (2025年4月9日 周三)

* 一个对称矩阵如果其所有特征值都严格为正，则它是**正定 (PD)** 的。
* 一个对称矩阵如果其所有特征值都非负，则它是**半正定 (PSD)** 的。
* 如果 $A$ 是对称的，它为 PD 当且仅当对于每个向量 $x$，$x^\top Ax>0$。
* 如果 $A$ 是对称的，它为 PSD 当且仅当对于每个向量 $x$，$x^\top Ax\ge0$。
* 对于任何矩阵 $M$ ($n\times p$)，$MM^\top$ 和 $M^\top M$ 都是半正定的。
* 在这节课上，我们介绍了**奇异值分解 (SVD)**，它适用于任何矩阵 $M$ ($n\times p$)。更准确地说，我们讲了长 SVD 和短 SVD。
* 在 $M$ 是一个满秩方块矩阵的特殊情况下，长 SVD 和短 SVD 是相同的，我们在课堂上讲解了找到这种 SVD 的过程。

**阅读材料：** Strang 教材 7.1节。

### 第25讲 (2025年4月11日 周五)

* 我们讲解了如何找到一个一般矩阵 $M$ ($n\times p$) 的短 SVD 和长 SVD。
* 矩阵 $A=M^\top M$ 是半正定的，所以我们可以找到它的谱分解 $A=EDE^\top$。此外，我们可以将 $D$ 的对角线元素排列为 $d_1 \ge \ldots \ge d_r > 0 = d_{r+1} = \ldots = d_p$，其中 $r$ 是 $M$ 的秩（也是 $A$ 的秩）。
* 设 $V$ 是由 $E$ 的前 $r$ 列组成的 $p\times r$ 矩阵。
* 设 $\Sigma$ 是 $r\times r$ 的对角矩阵，其对角线元素为 $\sigma_i=(d_i)^{1/2}$，$1\le i\le r$。
* 设 $U$ 是由 $U=MV\Sigma^{-1}$ 定义的 $n\times r$ 矩阵。
* 那么 $M=U\Sigma V^\top$ 给出 $M$ 的短 SVD。
* 从短 SVD 转换为长 SVD：将 $\Sigma$ 从 $r\times r$ 扩展到 $n\times p$（通过添加零）；将 $U$ 从 $n\times r$ 扩展到 $n\times n$，使其列构成 $\mathbb{R}^n$ 的一个标准正交基；将 $V$ 从 $p\times r$ 扩展到 $p\times p$，使其列构成 $\mathbb{R}^p$ 的一个标准正交基。
* 我们还讨论了一些例子和练习题。

**阅读材料：** 完成阅读 Strang 教材 7.1节。

### 第26讲 (2025年4月16日 周三)

* 在这节课上，我们讲解了 SVD 的几何解释。
* 假设 $M$ 是一个秩为 $r$ 的 $n\times p$ 矩阵，并且我们将其奇异值按非增顺序排列 $\sigma_1\ge \ldots \ge \sigma_r>0$。
* 最大奇异值 $\sigma_1$ 是 $M$ 的*算子范数*或*谱范数*，通常记为 $\|M\|_\textup{op}$ 或 $\|M\|$。
* $M$ 的算子范数可以理解为当 $v$ 遍历 $\mathbb{R}^p$ 中所有单位向量时，$\|Mv\|$ 所能达到的最大值。
* SVD 可用于计算伪逆：如果 $M$ 的短 SVD 为 $M=U\Sigma V^\top$，那么 $M$ 的伪逆是 $V\Sigma^{-1}U^\top$。

**阅读材料：** Strang 教材 7.2节。

### 第27讲 (2025年4月18日 周五)

* 在这节课上，我们讲解了 SVD 在低秩近似和图像压缩中的应用。
* 假设 $M$ 是一个 $n\times p$ 矩阵，其短 SVD 为 $M=U\Sigma V^\top$。像往常一样，我们按大小排列奇异值（$\Sigma$ 的对角线元素）$\sigma_1\ge \ldots \ge \sigma_r>0$。
* $M$ 的秩为 $k$ 的近似由 $M_k = U_k \Sigma_k (V_k)^\top$ 给出，其中 $U_k$ 由 $U$ 的前 $k$ 列组成，$V_k$ 由 $V$ 的前 $k$ 列组成，$\Sigma_k$ 是 $\Sigma$ 的左上角 $k\times k$ 子矩阵。
* 我们讨论了三种矩阵范数：(1) 算子范数/谱范数；(2) 弗罗贝尼乌斯范数/希尔伯特-施密特范数；(3) 核范数。
* Eckhart-Young 定理：在所有秩最多为 $k$ 的矩阵中，$M_k$ 是对 $M$ 的最佳近似。它在上述三种范数下都是最佳的。
* 在图像压缩中的应用：如果 $M$ 代表一个 $n\times p$ 的图像，原始图像包含 $np$ 个像素。存储压缩后的图像 $M_k$ 需要存储 $(n+p)k+k$ 个值。如果 $n,p$ 很大而 $k$ 相对较小，压缩后的图像需要少得多的存储空间。
* 例子参见 https://timbaumann.info/svd-image-compression-demo/。

**阅读材料：** Strang 教材 7.2节。

### 第28讲 (2025年4月23日 周三)

* 我们讲解了 SVD 在 PCA（主成分分析）中的应用。
* 设 $X$ 是一个 $n\times p$ 的数据矩阵，其中 $n$ 是个体或样本的数量，$p$ 是属性或特征的数量。
* 我们假设数据是标准化的，即每一列（特征）的均值为零，标准差为一。
* 二维 PCA：选择数据的二维投影，使其显示出最大的变异性。
* 我们在课堂上学到，这是通过选取 $u,v$ 为两个最大的右奇异向量（对应于 $V$ 矩阵的前两列）来实现的，从而得到 $i=1,\ldots,n$ 的值 $(x_i\cdot u,x_i\cdot v)$ 的二维散点图。
* 最后，我们证明了一维 PCA 和普通最小二乘法（OLS，见第12讲）是不同的。这就是为什么教材将一维 PCA 称为“垂直最小二乘法”的原因。

**阅读材料：** Strang 教材 7.3节。

### 第29讲 (2025年4月25日 周五)

* 在这节课上，我们通过讨论论文 https://doi.org/10.1038/nature07331 中涵盖的应用，结束了对 SVD 和 PCA 的讨论。
* 我们复习了复数的基础知识：实部、虚部、复共轭、模、极坐标形式、欧拉公式。
* 例子：对应于排列 $\sigma$（将 $1\mapsto 2, 2\mapsto 3, \ldots, n-1\mapsto n, n\mapsto1$）的排列矩阵 $A$。其特征值是单位的 $n$ 次根。
* 例子：求解微分方程 $f''(t)=-f(t)$。
* 我们定义了复数点积（也称标量积或内积）：对于 $v,w\in\mathbb{C}^n$，我们定义 $v\cdot w = \overline{v}^\top w$。

**阅读材料：** 开始阅读 Strang 教材 6.4节。

### 第30讲 (2025年4月28日 周一)

* 在这节课上，我们讲解了特殊类型的复 $n\times n$ 矩阵的定义。
* **酉 (Unitary)** 矩阵：**正交**矩阵定义的扩展。正交矩阵保持 $\mathbb{R}^n$ 标量积，而酉矩阵保持 $\mathbb{C}^n$ 标量积。
* **厄米 (Hermitian)** 矩阵：**对称**矩阵定义的扩展。对称矩阵在 $\mathbb{R}^n$ 上是自伴的，而厄米矩阵在 $\mathbb{C}^n$ 上是自伴的。
* 一个矩阵 $A\in\mathbb{C}^{n\times n}$ 如果满足 $A\bar{A}^\top=\bar{A}^\top A$，则它是**正规 (normal)** 的。酉矩阵集和厄米矩阵集都位于正规矩阵集之内。
* 我们讲解了三种情况下的**谱定理**：对称矩阵（之前已讲过）、厄米矩阵和正规矩阵。
* 例子：与上次讨论的相同的排列矩阵。该矩阵是正规的，但不是对称的。它有一个正交的特征基，这对应于 $\mathbb{C}^n$ 的一个特殊基，称为**傅里叶基**。

**阅读材料：** 继续阅读 Strang 教材 6.4节。

### 第31讲 (2025年4月30日 周三)

* 设 $P$ 为对应于循环排列 $\sigma$（将 $1\mapsto2, 2\mapsto 3, \ldots, n-1\mapsto n, n\mapsto 1$）的 $n\times n$ 排列矩阵。
* 我们回顾了 $P$ 的特征值是单位的 $n$ 次根，并且**傅里叶基**（$n\times n$ **傅里叶矩阵**的列）是 $P$ 的一个特征基。
* 因此，傅里叶基也是 $P$ 的任何（非负）次幂的特征基。
* 一个**循环矩阵**是 $P$ 的幂的任意线性组合。它通常出现在某些底层系统具有循环结构的情况下。例如，我们定义了循环图 $T_n$，它由 $n$ 个节点和 $n$ 条边连接成一个环：应用于 $T_n$ 上函数的离散导数的自然定义会产生一个循环矩阵。
* 傅里叶基也是任何循环矩阵的特征基。这个事实可以用来乘以循环矩阵，也意味着循环矩阵彼此之间可以交换。

**阅读材料：** 继续阅读 Strang 教材 6.4节。

### 第32讲 (2025年5月2日 周五)

* 在这节课上，我们继续讨论**循环矩阵**。我们详细讲解了**循环卷积**操作。
* 我们介绍了 $T_n$ 作为一个有 $n$ 个顶点的图，顶点编号从 $0$ 到 $n-1$，使用模 $n$ 的循环索引，使得 $i$ 和 $i+1$ 之间有边（因此，使用循环索引，在 $n-1$ 和 $0$ 之间有边）。一个向量 $f=(f_0,\ldots,f_{n-1})\in\mathbb{C}^n$ 等价于一个函数 $f:T_n\to\mathbb{C}$，它将元素 $j\in T_n$ 映射到值 $f(j)=f_j$。
* 我们讨论了对于函数 $f:T_n\to\mathbb{C}$，$f$ 的离散导数的一个自然概念可以表示为应用一个循环矩阵，$f\mapsto Df$。
* 我们还定义了一个离散二阶导数 $\Delta$，我们发现它也是一个循环矩阵。这个矩阵核中的向量对应于所谓的**调和**函数。

**阅读材料：** 继续阅读 Strang 教材 6.4节。

### 第33讲 (2025年5月5日)

* 在这节课上，我们讨论了复向量空间。
* 我们在复向量空间的背景下回顾了生成空间、线性无关、基、维数等基本概念。
* 我们在装备了 $\mathbb{C}^n$ 点积的 $\mathbb{C}^n$ 子空间的背景下回顾了正交投影的计算。
* 为了准备下一堂课，我们回顾了 $6\times6$ 傅里叶矩阵的精确结构。

**阅读材料：** 继续阅读 Strang 教材 6.4节。

### 第34讲 (2025年5月7日)

* 在这节课上，我们回顾了傅里叶基，并详细讲解了它与正弦-余弦基的联系。
* 我们讲解了离散傅里叶变换 (DFT)，并解释了如何将其视为一种基变换操作。
* 我们讨论了 DFT 在信号处理中压缩和去噪的自然应用。

**阅读材料：** 继续阅读 Strang 教材 6.4节。

### 第35讲 (2025年5月9日)

* 这节课的重点是 DFT 将卷积转换为点乘。这是傅里叶变换的一个关键性质。
* 我们利用之前学到的关于循环矩阵的知识，给出了这个恒等式的代数推导。
* 我们讲解了这个恒等式的一些用途：例如，由于卷积可能很复杂（比如考虑一个向量 $x$ 的 $n$ 重卷积），我们可以使用 DFT 将卷积转换为点乘——这很简单——然后应用傅里叶逆变换转换回来。

**阅读材料：** 继续阅读 Strang 教材 6.4节。

### 第36讲 (2025年5月12日)

* 在这节课上，我们对上次的同一个事实——DFT 将卷积转换为点乘——给出了一个**概率**推导。
* 我们还回顾了之前关于 SVD 的一些材料。

**阅读材料：** 完成阅读 Strang 教材 6.4节。
```
